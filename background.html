<HTML>

<head>
<TITLE>Who I am</TITLE>
<style>
th, td
{
    padding: 5px;
}
</style>
</head>

<BODY bgcolor="#E6E6FA">
<H3>Professional Experience</H3>
<b>Research and Development at <a href="https://health.google/health-research/" target=_blank>Google Health Research</a>, Palo Alto, California</b>, <i>September 2018 - February 2020</i>
<p>As a part of Google Health, I led the project "Graph Convolutional Transformer", which aimed to capture the hidden graphical structure of electronic health records (EHR) to gain better prediction performance. This work was <a href="https://arxiv.org/pdf/1906.04716.pdf" target=_blank>presented at AAAI 2020</a>. I also participated in a project to analyze how the model uncertainty affects the neural network prediction models for EHR data, which was <a href="https://arxiv.org/pdf/1906.03842.pdf" target=_blank>presented at CHIL 2020</a>.
</p>
<b>Research Internship at <a href="http://research.google.com" target=_blank>Google Research</a>, Mountain View, California</b>, <i>May 2017 - Aug 2017</i>
<p>I was a member of the project team named <a href="https://arxiv.org/pdf/1711.06798.pdf" target=_blank>MorphNet</a>. The objective was to automatically learn the structure of neural networks given some resource constraint (e.g. number of parameters, number of FLOPs), using various regularization methods. My specific task was related to NLP applications and I modified several variable selection algorithms such as Smoothly Clipped Absolute Deviation (SCAD) to activate/deactivate groups of parameters. MorphNet was <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Gordon_MorphNet_Fast__CVPR_2018_paper.html" target=_blank>presented at CVPR 2018</a>.
</p>
<b>Research Internship at <a href="http://deepmind.com" target=_blank>DeepMind</a>, London, U.K.</b>, <i>Feb 2017 - May 2017</i>
<p>My first project was to train an embodied agent to find out the heaviest object in a virtual environment. This was an extended work of "Which is heavier?" experiment from <a href="https://openreview.net/forum?id=r1nTpv9eg&noteId=r1nTpv9eg" target=_blank>Learning to Perform Physics Experiments via Deep Reinforcement Learning (Denil et al. ICLR 2017)</a>. The agent was equipped with a hammer to probe the objects, and a positive reward was given when the hammer was in contact with the heaviest object (hence the project name Pinata). The agent successfully learned to interact with the objects and stick to the heaviest one (<a href="https://youtu.be/gs7mWG2sjUU" target=_blank>example video 1</a>, <a href="https://youtu.be/vqYzBsuqYPs" target=_blank>example video 2</a>).<br>
My second project was training neural agents to develop compositional language purely from raw pixels by playing an image description game.
By employing a communication strategy named Obverter, which is motivated by the theory of mind, we confirmed the two agents could develop a highly structured/patterned communication protocol. This work will be <a href="https://openreview.net/forum?id=rknt2Be0-" target=_blank>presented in ICLR 2018</a>.
</p>
<b>Internship at Research, Development and Dissemination (RD&D), <a href="http://www.sutterhealth.org" target=_blank>Sutter Health</a>, California</b>, <i>May 2016 - August 2016</i>
<p>In my second internship at Sutter Health, I focused on developing interpretable deep learning models for predictive healthcare. Specifically, using the neural attention mechanism combined with RNN and MLP, I was able to design a sequence prediction model that demonstrated similar AUC as RNN but completely interpretable; the model allowed precise calculation of how much each diagnosis/medication/procedure in the past visits contributed to the final prediction. This work, named RETAIN, was <a href="https://papers.nips.cc/paper/6321-retain-an-interpretable-predictive-model-for-healthcare-using-reverse-time-attention-mechanism" target=_blank>presented in NIPS 2016</a>.
</p>
<b>Internship at Research, Development and Dissemination (RD&D), <a href="http://www.sutterhealth.org" target=_blank>Sutter Health</a>, California</b>, <i>May 2015 - August 2015</i>
<p>During the internship, I explored the potential of applying deep learning methods to health care problems, specifically predicting the future heart failure diagnosis. Applying stacked de-noising auto encoders to heart failure prediction enabled sophisticated analysis of the relation between patient features and heart failure diagnosis. Furthermore, through the combination of the word embedding technique and recurrent neural networks, I was able to improve the heart failure prediction performance from 0.81 AUC to 0.86 AUC. This work was <a href="https://academic.oup.com/jamia/article/24/2/361/2631499" target=_blank>published in JAMIA</a>.
</p>
<b>Research and development at Knowledge Mining Research Team, <a href="http://www.etri.re.kr" target=_blank>Electronics and Telecommunications Research Institute (ETRI)</a>, South Korea</b>, <i>February 2010 - April 2014</i>
<p>My first task was to build a Hadoop and HBase cluster to process Big Data (news, blogs, Tweets). Then I taught myself to write MapReduce codes for text analysis. This changed the way my team process text data, from dealing several tens of thousand documents on a few separate machines to systematically analyzing millions of documents per day on a cluster and saving the results to a distributed database. Then I worked on Named Entity Recognition module and Event Extraction module, while simultaneously studying machine learning techniques. I also developed solvers for Binary SVM, Structural SVM, One-class SVM, Ranking SVM in C++ and Java.</p>
Project Participation
<ul>
    <li>Development of Web QA (Question Answering) Technology, <i>February 2010 - February 2011</i></li>
    <li>Development of Social Web Issue Detection-Monitoring and Prediction Technology for Big Data Analytic Listening Platform of Web Intelligence, <i>March 2011 - February 2013</i></li>
    <li>Development of Knowledge Evolutionary WiseQA Platform Technology for Human Knowledge Augmented Services, <i>May 2013 - April 2014</i></li>
</ul>

<HR>
<H3>Education</H3>
<ul>
    <li><a href="http://www.gatech.edu" target=_blank>Georgia Institute of Technology</a>, USA, <i>August 2014 - August 2018</i></li>
    Ph.D. in Computer Science (Specific Field: Interpretable Deep Learning for Healthcare)<br>
    Advisor: <a href="http://www.sunlab.org" target=_blank>Jimeng Sun</a><br><br>
    <li><a href="http://www.kaist.ac.kr" target=_blank>Korea Advanced Institute of Science and Technology</a>, South Korea, <i>August 2007 - August 2009</i></li>
    M.S. in Computer Science (Specific Field: Natural Language Processing)<br>
    Advisor: <a href="http://nlpcl.kaist.ac.kr" target=_blank>Jong C. Park</a><br><br>
    <li><a href="http://www.snu.ac.kr" target=_blank>Seoul National University</a>, South Korea, <i>March 2002 - August 2007</i></li>
    B.S. in Computer Science and Engineering (Minor in Applied Biochemistry)<br>
</ul>
</BODY>
</HTML>
